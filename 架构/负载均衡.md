### vhost

	upstream loadbalance{
	#设定负载均衡配置名称
	server 127.0.0.1:8081;  //设定主机1 ip+端口
	server 127.0.0.1:8082;  //设定主机2 ip+端口
	}
	server {
	listen       80;
	server_name  load-balance.com;
	location / {
	        proxy_pass  http://loadbalance;
	    }
	access_log  /opt/software/nginx/logs/load-balance.access;
	error_log  /opt/software/nginx/logs/load-balance.error;
	}
	server {
		listen 8081;
		server_name 127.0.0.1;
		index index.html;
		location /{
			root /opt/work/load-balance1.com;
		}
	}
	server {
		listen 8082;
		server_name 127.0.0.1;
		index index.html;
		location /{
			root /opt/work/load-balance2.com;
		}
	}

### 测试结果

- 交替显示load-balance1 load-balance2下的index.html
- 可以设置权重，是否参与负载

### 104: Connection reset by peer

>这种错误大抵会出现在本地测试过程中，如果你用了host映射

	upstream loadbalance{
		#设定负载均衡配置名称
		server load-balance1.com;  //设定主机1 ip+端口
		server load-balance2.com;  //设定主机2 ip+端口
	}
	
	hosts
	127.0.0.1 load-balance1.com
	127.0.0.1 load-balance2.com

这里建议指定ip+port





#### 负载均衡

负载均衡的实现方法就是我们上章介绍的反向代理 。将客户的请求通过 nginx 分发（反向代理）到一组多台不同的服务器上

这一组服务器我们称为 服务池（upstream server），池内的每一个服务器称为一个 单元，服务池内将对每一个单元进行请求轮训，实现负载均衡

	#配置
	语法：upstream name ...
	默认：——
	位置：http


	upstream #自定义组名 {
	server x1.baidu.com;    #可以是域名
	server x2.baidu.com;
	#server x3.baidu.com
	                        #down         不参与负载均衡
	                        #weight=5;    权重，越高分配越多
	                        #backup;      预留的备份服务器
	                        #max_fails    允许失败的次数
	                        #fail_timeout 超过失败次数后，服务暂停时间
	                        #max_coons    限制最大的接受的连接数
	                        #根据服务器性能不同，配置适合的参数
	
	#server 106.xx.xx.xxx;        可以是ip
	#server 106.xx.xx.xxx:8080;   可以带端口号
	#server unix:/tmp/xxx;        支出socket方式
	}


假设我们有三台服务器，并且假设它们的IP地址，前端负载均衡服务器A（127.0.0.1），后台服务器B（127.0.0.2），后台服务器C（127.0.0.3）

新建文件 proxy.conf，内容如下，上一章介绍的反向代理配置



	proxy_redirect default;
	proxy_set_header Host $http_host;
	proxy_set_header X-Real-IP $remote_addr;
	proxy_connect_timeout 30;
	proxy_send_timeout 60;
	proxy_read_timeout 60;
	proxy_buffer_size 32k;
	proxy_buffering on;
	proxy_buffers 4 128k;
	proxy_busy_buffers_size 256k;
	proxy_max_temp_file_size 256k;


	#服务器A的配置
	http {
	    ...
	    upstream xxx {
	        server 127.0.0.2;
	        server 127.0.0.3;
	    }
	    server {
	        liseten 80;
	        server_name localhost;
	        location / {
	            proxy_pass http://xxx     #upstream 对应自定义名称
	            include proxy.conf;
	        }
	    }
	}
	
	#服务器B、服务器C的配置
	server {
	    liseten 80;
	    server_name localhost;
	    location / {
	         index  index.html
	    }
	}


调度算法

* 轮训：按时间顺序逐一分配到不同的后端服务器
* 加权轮训：weight值越大，分配到的几率越高
* ip_hash：每个请求按访问IP的hash结果分配，这样来自同一个IP固定访问一个后端服务器
* least_conn：最少链接数，哪个机器连接数少就分发给谁
* url_hash：按照访问的URL的hash结果来分配请求，每一个URL定向到同一个后端服务器
* hash关键数值：hash自定义key

ip_hash 配置

	 upstream xxx {
	        ip_hash;
	        server 127.0.0.2;
	        server 127.0.0.3;
	  }

ip_hash存在缺陷，当前端服务器再多一层时，将获取不到用户的正确IP，获取的将是前一个前端服务器的IP，因此 nginx1.7.2版本推出了 url_hash

url_hash 配置

	 upstream xxx {
	    hash $request_uri;
	    server 127.0.0.2;
	    server 127.0.0.3;
 	 }